{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from utils import load_embeddings_and_ids, concatenate_featmats\n",
    "from Networks import CuratorNet_Precomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = load_embeddings_and_ids('../data/resnet_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = [\n",
    "    resnet50,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artwork_ids_set = set()\n",
    "for embedding in embedding_list:\n",
    "    if len(artwork_ids_set) == 0:        \n",
    "        artwork_ids_set.update(embedding['index2id'].values())\n",
    "    else:\n",
    "        artwork_ids_set.intersection_update(embedding['index2id'])\n",
    "artwork_ids = list(artwork_ids_set)\n",
    "artwork_id2index = {_id:i for i,_id in enumerate(artwork_ids)}\n",
    "n_artworks = len(artwork_ids)\n",
    "n_artworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "featmat_list = [tmp['featmat'] for tmp in embedding_list]\n",
    "id2index_list = [tmp['id2index'] for tmp in embedding_list]\n",
    "concat_featmat = concatenate_featmats(artwork_ids, featmat_list, id2index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_featmat = StandardScaler().fit_transform(concat_featmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 2048)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_featmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O volume na unidade C nÆo tem nome.\n",
      " O N£mero de S‚rie do Volume ‚ 789E-3B0A\n",
      "\n",
      " Pasta de C:\\Users\\victor_accete\\CuratorNet\\experiments\\curatornet_10m\n",
      "\n",
      "08/02/2022  22:02    <DIR>          .\n",
      "08/02/2022  22:02    <DIR>          ..\n",
      "08/02/2022  22:02         8.649.608 .data-00000-of-00001\n",
      "08/02/2022  22:02             1.204 .index\n",
      "08/02/2022  22:02           239.676 .meta\n",
      "08/02/2022  22:02               191 checkpoint\n",
      "08/02/2022  22:02             1.634 train_logs.csv\n",
      "               5 arquivo(s)      8.892.313 bytes\n",
      "               2 pasta(s)   151.067.615.232 bytes dispon¡veis\n"
     ]
    }
   ],
   "source": [
    "!dir C:\\Users\\victor_accete\\CuratorNet\\experiments\\curatornet_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\victor_accete\\\\CuratorNet\\\\experiments\\\\curatornet_10m\\\\'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"C:\\\\Users\\\\victor_accete\\\\CuratorNet\\\\experiments\\\\curatornet_10m\\\\\"\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victor_accete\\CuratorNet\\experiments\\curatornet_10m\\\n"
     ]
    }
   ],
   "source": [
    "print(tf.train.latest_checkpoint(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B2F9027400>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From C:\\Users\\victor_accete\\Anaconda3\\envs\\CuratorNet\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\victor_accete\\CuratorNet\\experiments\\curatornet_10m\\\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    network = CuratorNet_Precomputation(\n",
    "        pretrained_embedding_dim=concat_featmat.shape[1],\n",
    "        item_layer_units=[200,200],\n",
    "    )\n",
    "    gpu_options = tf.GPUOptions(\n",
    "            per_process_gpu_memory_fraction=0.99,\n",
    "            allow_growth=True\n",
    "        )\n",
    "    config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(MODEL_PATH))\n",
    "        item_vectors = network.precompute_tensors(sess, concat_featmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13297, 200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors.dump(MODEL_PATH + \"item_vectors.npy\")\n",
    "with open(MODEL_PATH + 'ids', 'w') as f:\n",
    "    for _id in artwork_ids:\n",
    "        f.write('%s\\n' % _id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuratorNetKernel",
   "language": "python",
   "name": "curatornetkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
